#!/usr/bin/env python

# script to harvest and prep entire dataset, start to finish

import argparse
import glob
import os

from belfastdata.harvest import HarvestRdf, HarvestRelated
from belfastdata.qub import QUB
from belfastdata.clean import SmushGroupSheets, IdentifyGroupSheets, \
    InferConnections
from belfastdata.nx import Rdf2Gexf

# settings

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

harvest_urls = [
    # for now, harvest from test FA site, and only harvest
    # documents with tagged names
    'http://testfindingaids.library.emory.edu/documents/longley744/',
    'http://testfindingaids.library.emory.edu/documents/ormsby805/',
    'http://testfindingaids.library.emory.edu/documents/irishmisc794/',
    'http://testfindingaids.library.emory.edu/documents/carson746/',
    'http://testfindingaids.library.emory.edu/documents/heaney960/',
    'http://testfindingaids.library.emory.edu/documents/heaney653/',
    'http://testfindingaids.library.emory.edu/documents/muldoon784/',
    'http://testfindingaids.library.emory.edu/documents/simmons759/',
    'http://testfindingaids.library.emory.edu/documents/hobsbaum1013/',
    'http://testfindingaids.library.emory.edu/documents/mahon689/',

    # NOTE: once in production, related collections links should help


    # RDF from TEI group sheets (local dev urls for now)
    'http://testbeck.library.emory.edu/belfast/groupsheets/longley1_10244/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/longley1_10353/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/heaney1_10407/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/carson1_1035/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/longley1_10202/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/heaney1_10415/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/heaney1_10365/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/heaney1_10163/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/heaney1_10199/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/heaney1_10236/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/heaney1_10269/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/longley1_1042/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/heaney1_10442/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/hobsbaum1_1040/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/heaney1_10116/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/heaney1_1078/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/heaney1_1041/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/muldoon2_10121/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/muldoon2_1079/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/muldoon2_1040/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/longley1_10120/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/longley1_10158/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/longley1_1079/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/longley1_10282/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/longley1_10316/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/simmons1_1035/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/simmons1_1069/',
    'http://testbeck.library.emory.edu/belfast/groupsheets/hobsbaum1_1047/'

]


# build relative to script or current directory?
output_dir = 'data'
# using n3 because it is smaller and more efficient to serialize & load
output_format = 'n3'

QUB_input = os.path.join(BASE_DIR, '..', 'belfastdata', 'QUB_ms1204.html')

gexf_file = os.path.join(output_dir, 'belfastgroup.gexf')

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Harvest and prep Belfast Group RDF dataset')
    steps = parser.add_argument_group(
        'steps',
        'Data processing steps to run.  Specify one or more to only run those ' +
        'steps.  If not are specified, all steps will be run in order.')
    steps.add_argument('-v', '--harvest', action='store_true',
                       help='Harvest RDFa')
    steps.add_argument('-q', '--queens', action='store_true',
                       help='Convert Queens University Belfast collection to RDF')
    steps.add_argument('-r', '--related', action='store_true',
                       help='Harvest related RDF from VIAF, GeoNames, and DBpedia')
    steps.add_argument('-i', '--infer', action='store_true',
                       help='Identify group sheets')
    steps.add_argument('-s', '--smush', action='store_true',
                       help='Smush groupsheet URIs')
    steps.add_argument('-c', '--connect', action='store_true',
                       help='Infer and connections implicit in the data')
    steps.add_argument('-g', '--gexf', action='store_true',
                       help='Generate GEXF network graph data')
    # TODO: configurable verbosity ?
    # parser.add_argument('-v', '--verbosity', metavar='VERBOSITY', type=int,
    #                     choices=[0, 1, 2], default=1,
    #                     help='Verbosity level; 0=minimal, 1=normal, 2=verbose')

    # TODO: add an option to specify where the output should be generated

    args = parser.parse_args()
    # if specific steps are specified, run only those
    # otherwise, run all steps
    all_steps = not any([args.harvest, args.queens, args.related, args.smush,
                         args.gexf, args.infer, args.connect])

    if all_steps or args.harvest:
        print '-- Harvesting RDF from EmoryFindingAids related to the Belfast Group'
        HarvestRdf(harvest_urls, output_dir=output_dir,
                   find_related=True, verbosity=0, format=output_format)

    if all_steps or args.queens:
        print '-- Converting Queens University Belfast Group collection description to RDF'
        QUB(QUB_input, output_dir, verbosity=0, output_format=output_format)

    # files needed for harvest related, smushing, and gexf
    files = glob.glob(os.path.join(output_dir, '*.%s' % output_format))
    # NOTE: can't use iglob here if we want to use the same list in multiple steps
    # if we ever get so many files we need that, will have to get the list
    # for each step individually

    if all_steps or args.related:
        print '-- Harvesting related RDF from VIAF, GeoNames, and DBpedia'
        # TODO: add logic so unchanged content isn't re-downloaded
        # (use last-modified http header & file date)
        HarvestRelated(files, output_dir, format=output_format)

    if all_steps or args.infer:
        # smush any groupsheets in the data
        print '-- Identifying groupsheets'
        IdentifyGroupSheets(files)

    if all_steps or args.smush:
        # smush any groupsheets in the data
        print '-- Smushing groupsheet URIs'
        SmushGroupSheets(files)

    if all_steps or args.connect:
        # infer connections
        print '-- Inferring connections: groupsheet authors affiliated with group'
        InferConnections(files)
        # TODO: groupsheet owner based on source collection

    if all_steps or args.gexf:
        # generate gexf
        print '-- Generating network graph and saving as GEXF'
        Rdf2Gexf(files, gexf_file, format=output_format)
